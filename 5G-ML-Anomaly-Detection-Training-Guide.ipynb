{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0358915",
   "metadata": {},
   "source": [
    "# 5G網路ML異常偵測模型訓練完整指南\n",
    "\n",
    "## 概述\n",
    "\n",
    "本筆記詳細說明如何在5G網路環境中訓練機器學習異常偵測模型，包含完整的訓練流程、特徵工程、模型選擇、評估方法等。\n",
    "\n",
    "### 系統架構\n",
    "- **MLAnomalyDetector**: 核心機器學習異常偵測器\n",
    "- **MLFeatureExtractor**: 特徵提取器\n",
    "- **RealTimeAnomalyDetector**: 實時異常偵測系統\n",
    "- **TestSelector**: 整合測試系統\n",
    "\n",
    "### 支援的ML模型\n",
    "1. **Isolation Forest** (無監督) - 推薦用於測試\n",
    "2. **One-Class SVM** (無監督)\n",
    "3. **Random Forest** (監督式) - 需要標記數據\n",
    "4. **DBSCAN** (無監督聚類)\n",
    "\n",
    "### 應用場景\n",
    "- 5G gNB隨機接入(RA)程序異常偵測\n",
    "- 網路攻擊檢測\n",
    "- 信號干擾檢測\n",
    "- 設備故障診斷"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3731e7",
   "metadata": {},
   "source": [
    "## 1. 導入必要的函式庫\n",
    "\n",
    "首先導入機器學習訓練所需的所有Python函式庫。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072740ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入核心機器學習函式庫\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 導入scikit-learn機器學習模型\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    roc_auc_score, roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# 導入其他必要函式庫\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "\n",
    "# 設定顯示選項\n",
    "plt.style.use('default')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✅ 所有必要函式庫已成功導入\")\n",
    "print(f\"NumPy版本: {np.__version__}\")\n",
    "print(f\"Pandas版本: {pd.__version__}\")\n",
    "print(f\"Matplotlib版本: {matplotlib.__version__}\")\n",
    "print(f\"Scikit-learn版本: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e31512",
   "metadata": {},
   "source": [
    "## 2. 建立ML異常偵測器類別\n",
    "\n",
    "`MLAnomalyDetector`是核心的機器學習異常偵測器，支援多種ML算法並提供統一的訓練和預測介面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8736325",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLAnomalyDetector:\n",
    "    \"\"\"\n",
    "    機器學習異常偵測器 - 使用多種ML算法進行5G網路異常偵測\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_type: str = 'isolation_forest'):\n",
    "        \"\"\"\n",
    "        初始化ML異常偵測器\n",
    "        \n",
    "        參數:\n",
    "            model_type: 模型類型 ('isolation_forest', 'one_class_svm', 'random_forest', 'dbscan')\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.is_trained = False\n",
    "        self.feature_names = []\n",
    "        self.threshold = 0.5\n",
    "        \n",
    "        # 初始化選定的模型\n",
    "        self._initialize_model()\n",
    "        print(f\"✅ MLAnomalyDetector初始化完成，模型類型: {model_type}\")\n",
    "    \n",
    "    def _initialize_model(self):\n",
    "        \"\"\"根據模型類型初始化對應的ML模型和數據標準化器\"\"\"\n",
    "        \n",
    "        if self.model_type == 'isolation_forest':\n",
    "            # Isolation Forest: 基於隔離的異常偵測\n",
    "            self.model = IsolationForest(\n",
    "                contamination=0.1,      # 預期異常比例10%\n",
    "                random_state=42,\n",
    "                n_estimators=100,       # 決策樹數量\n",
    "                max_samples='auto',     # 每棵樹的樣本數\n",
    "                bootstrap=False\n",
    "            )\n",
    "            self.scaler = StandardScaler()\n",
    "            \n",
    "        elif self.model_type == 'one_class_svm':\n",
    "            # One-Class SVM: 單類支持向量機\n",
    "            self.model = OneClassSVM(\n",
    "                kernel='rbf',           # 徑向基核函數\n",
    "                gamma='scale',          # 核函數係數\n",
    "                nu=0.1                  # 異常比例上界\n",
    "            )\n",
    "            self.scaler = StandardScaler()\n",
    "            \n",
    "        elif self.model_type == 'random_forest':\n",
    "            # Random Forest: 隨機森林分類器（監督學習）\n",
    "            self.model = RandomForestClassifier(\n",
    "                n_estimators=100,       # 決策樹數量\n",
    "                random_state=42,\n",
    "                class_weight='balanced', # 平衡類別權重\n",
    "                max_depth=10,           # 樹的最大深度\n",
    "                min_samples_split=5,    # 節點分割所需最小樣本數\n",
    "                min_samples_leaf=2      # 葉節點最小樣本數\n",
    "            )\n",
    "            self.scaler = RobustScaler()  # 對異常值更穩健\n",
    "            \n",
    "        elif self.model_type == 'dbscan':\n",
    "            # DBSCAN: 基於密度的聚類算法\n",
    "            self.model = DBSCAN(\n",
    "                eps=0.5,                # 鄰域半徑\n",
    "                min_samples=5,          # 核心點最小樣本數\n",
    "                metric='euclidean'      # 距離度量\n",
    "            )\n",
    "            self.scaler = StandardScaler()\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"不支援的模型類型: {self.model_type}\")\n",
    "    \n",
    "    def get_model_info(self) -> Dict:\n",
    "        \"\"\"獲取模型詳細資訊\"\"\"\n",
    "        return {\n",
    "            'model_type': self.model_type,\n",
    "            'is_trained': self.is_trained,\n",
    "            'feature_count': len(self.feature_names),\n",
    "            'feature_names': self.feature_names,\n",
    "            'threshold': self.threshold,\n",
    "            'model_params': self.model.get_params() if self.model else None\n",
    "        }\n",
    "\n",
    "# 創建示例偵測器\n",
    "detector_example = MLAnomalyDetector('isolation_forest')\n",
    "print(f\"模型資訊: {detector_example.get_model_info()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06872a14",
   "metadata": {},
   "source": [
    "## 3. 特徵提取與數據預處理\n",
    "\n",
    "特徵提取是ML異常偵測的關鍵步驟，我們從5G網路的RA統計數據、信號強度、時間戳等原始數據中提取有意義的特徵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLFeatureExtractor:\n",
    "    \"\"\"\n",
    "    機器學習特徵提取器 - 從5G網路數據中提取異常偵測特徵\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        \n",
    "    def extract_ra_features(self, ra_stats: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        從RA統計數據中提取特徵\n",
    "        \n",
    "        參數:\n",
    "            ra_stats: RA統計資料字典\n",
    "            \n",
    "        返回:\n",
    "            提取的RA特徵字典\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # 基本統計特徵\n",
    "        features['ra_success_rate'] = ra_stats.get('success_rate', 0)\n",
    "        features['ra_initiated'] = ra_stats.get('ra_initiated', 0)\n",
    "        features['ra_succeeded'] = ra_stats.get('ra_succeeded', 0)\n",
    "        features['ra_failed'] = ra_stats.get('failed_attempts', 0)\n",
    "        \n",
    "        # 衍生特徵\n",
    "        total_ra = ra_stats.get('ra_initiated', 1)\n",
    "        features['ra_frequency'] = total_ra / 20  # 假設20秒測試時間\n",
    "        features['failure_rate'] = ra_stats.get('failed_attempts', 0) / max(total_ra, 1)\n",
    "        features['success_efficiency'] = ra_stats.get('ra_succeeded', 0) / max(total_ra, 1)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def extract_timing_features(self, timestamps: List[float]) -> Dict:\n",
    "        \"\"\"\n",
    "        從時間戳序列中提取時序特徵\n",
    "        \n",
    "        參數:\n",
    "            timestamps: 時間戳列表\n",
    "            \n",
    "        返回:\n",
    "            時序特徵字典\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        if len(timestamps) < 2:\n",
    "            return {\n",
    "                'avg_interval': 0, 'interval_variance': 0, 'interval_std': 0,\n",
    "                'min_interval': 0, 'max_interval': 0, 'interval_range': 0\n",
    "            }\n",
    "        \n",
    "        # 計算時間間隔\n",
    "        intervals = np.diff(timestamps)\n",
    "        \n",
    "        # 統計特徵\n",
    "        features['avg_interval'] = np.mean(intervals)\n",
    "        features['interval_variance'] = np.var(intervals)\n",
    "        features['interval_std'] = np.std(intervals)\n",
    "        features['min_interval'] = np.min(intervals)\n",
    "        features['max_interval'] = np.max(intervals)\n",
    "        features['interval_range'] = np.max(intervals) - np.min(intervals)\n",
    "        \n",
    "        # 規律性特徵\n",
    "        if len(intervals) > 3:\n",
    "            # 計算相鄰間隔的變化率\n",
    "            interval_changes = np.abs(np.diff(intervals))\n",
    "            features['interval_stability'] = 1 / (1 + np.mean(interval_changes))\n",
    "        else:\n",
    "            features['interval_stability'] = 1\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def extract_signal_features(self, signal_data: List[float]) -> Dict:\n",
    "        \"\"\"\n",
    "        從信號強度數據中提取特徵\n",
    "        \n",
    "        參數:\n",
    "            signal_data: 信號強度列表\n",
    "            \n",
    "        返回:\n",
    "            信號特徵字典\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        if not signal_data:\n",
    "            return {\n",
    "                'signal_mean': 0, 'signal_std': 0, 'signal_variance': 0,\n",
    "                'signal_min': 0, 'signal_max': 0, 'signal_range': 0,\n",
    "                'signal_change_rate': 0\n",
    "            }\n",
    "        \n",
    "        signal_array = np.array(signal_data)\n",
    "        \n",
    "        # 基本統計特徵\n",
    "        features['signal_mean'] = np.mean(signal_array)\n",
    "        features['signal_std'] = np.std(signal_array)\n",
    "        features['signal_variance'] = np.var(signal_array)\n",
    "        features['signal_min'] = np.min(signal_array)\n",
    "        features['signal_max'] = np.max(signal_array)\n",
    "        features['signal_range'] = np.max(signal_array) - np.min(signal_array)\n",
    "        \n",
    "        # 信號變化特徵\n",
    "        if len(signal_data) > 1:\n",
    "            signal_diff = np.diff(signal_array)\n",
    "            features['signal_change_rate'] = np.mean(np.abs(signal_diff))\n",
    "            features['signal_trend'] = np.corrcoef(range(len(signal_array)), signal_array)[0, 1]\n",
    "        else:\n",
    "            features['signal_change_rate'] = 0\n",
    "            features['signal_trend'] = 0\n",
    "            \n",
    "        return features\n",
    "    \n",
    "    def extract_comprehensive_features(self, test_data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        提取綜合特徵向量\n",
    "        \n",
    "        參數:\n",
    "            test_data: 測試數據字典\n",
    "            \n",
    "        返回:\n",
    "            完整的特徵字典\n",
    "        \"\"\"\n",
    "        all_features = {}\n",
    "        \n",
    "        # RA程序特徵\n",
    "        if 'ra_stats' in test_data:\n",
    "            ra_features = self.extract_ra_features(test_data['ra_stats'])\n",
    "            all_features.update({f'ra_{k}': v for k, v in ra_features.items()})\n",
    "        \n",
    "        # 時序特徵\n",
    "        if 'timestamps' in test_data:\n",
    "            timing_features = self.extract_timing_features(test_data['timestamps'])\n",
    "            all_features.update({f'timing_{k}': v for k, v in timing_features.items()})\n",
    "        \n",
    "        # 信號特徵\n",
    "        if 'signal_data' in test_data:\n",
    "            signal_features = self.extract_signal_features(test_data['signal_data'])\n",
    "            all_features.update({f'signal_{k}': v for k, v in signal_features.items()})\n",
    "        \n",
    "        # 環境與配置特徵\n",
    "        all_features['test_duration'] = test_data.get('test_duration', 0)\n",
    "        all_features['attacker_present'] = 1 if test_data.get('attacker_active', False) else 0\n",
    "        all_features['airplane_mode_toggles'] = test_data.get('airplane_toggles', 0)\n",
    "        all_features['loop_number'] = test_data.get('loop_number', 0)\n",
    "        \n",
    "        # 測試類型編碼\n",
    "        test_type = test_data.get('test_type', 'unknown')\n",
    "        all_features['test_type_cots_only'] = 1 if test_type == 'cots_only' else 0\n",
    "        all_features['test_type_standard'] = 1 if test_type == 'standard' else 0\n",
    "        all_features['test_type_attacker_priority'] = 1 if test_type == 'attacker_priority' else 0\n",
    "        \n",
    "        return all_features\n",
    "\n",
    "# 創建特徵提取器並示範使用\n",
    "extractor = MLFeatureExtractor()\n",
    "\n",
    "# 示例數據\n",
    "sample_data = {\n",
    "    'ra_stats': {\n",
    "        'success_rate': 95.5,\n",
    "        'ra_initiated': 12,\n",
    "        'ra_succeeded': 11,\n",
    "        'failed_attempts': 1\n",
    "    },\n",
    "    'timestamps': [1.0, 2.5, 4.1, 6.2, 8.0],\n",
    "    'signal_data': [52.3, 54.1, 53.8, 55.2, 54.9],\n",
    "    'test_duration': 20,\n",
    "    'attacker_active': False,\n",
    "    'airplane_toggles': 4,\n",
    "    'loop_number': 1,\n",
    "    'test_type': 'cots_only'\n",
    "}\n",
    "\n",
    "# 提取特徵\n",
    "features = extractor.extract_comprehensive_features(sample_data)\n",
    "print(f\"✅ 成功提取 {len(features)} 個特徵\")\n",
    "print(\"特徵範例:\")\n",
    "for i, (key, value) in enumerate(list(features.items())[:10]):\n",
    "    print(f\"  {key}: {value:.3f}\")\n",
    "print(\"  ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a47f15",
   "metadata": {},
   "source": [
    "## 4. 合成訓練數據生成\n",
    "\n",
    "由於真實的5G網路異常數據難以取得，我們生成合成的訓練數據來模擬正常和異常的網路行為模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_training_data(num_normal=100, num_anomaly=30):\n",
    "    \"\"\"\n",
    "    生成合成的5G網路訓練數據\n",
    "    \n",
    "    參數:\n",
    "        num_normal: 正常樣本數量\n",
    "        num_anomaly: 異常樣本數量\n",
    "        \n",
    "    返回:\n",
    "        (normal_data, anomaly_data): 正常和異常數據列表\n",
    "    \"\"\"\n",
    "    \n",
    "    normal_data = []\n",
    "    anomaly_data = []\n",
    "    \n",
    "    print(f\"🔄 正在生成 {num_normal} 個正常樣本...\")\n",
    "    \n",
    "    # 生成正常行為數據\n",
    "    for i in range(num_normal):\n",
    "        # 正常情況：高成功率、穩定信號、規律時間間隔\n",
    "        ra_stats = {\n",
    "            'success_rate': np.clip(np.random.normal(95, 5), 85, 100),  # 高成功率\n",
    "            'ra_initiated': np.random.randint(8, 15),                   # 中等RA嘗試次數\n",
    "            'ra_succeeded': lambda x: np.random.randint(max(1, int(x*0.85)), x+1),\n",
    "            'failed_attempts': np.random.randint(0, 3)                  # 少量失敗\n",
    "        }\n",
    "        ra_stats['ra_succeeded'] = ra_stats['ra_succeeded'](ra_stats['ra_initiated'])\n",
    "        ra_stats['success_rate'] = (ra_stats['ra_succeeded'] / ra_stats['ra_initiated']) * 100\n",
    "        \n",
    "        # 正常時間戳：相對規律的間隔\n",
    "        base_interval = np.random.uniform(1.5, 3.0)\n",
    "        timestamps = []\n",
    "        current_time = 0\n",
    "        for _ in range(np.random.randint(8, 12)):\n",
    "            current_time += base_interval + np.random.normal(0, 0.3)  # 小的隨機變動\n",
    "            timestamps.append(current_time)\n",
    "        \n",
    "        # 正常信號：穩定且在合理範圍內\n",
    "        base_signal = np.random.uniform(48, 58)  # 正常信號強度範圍\n",
    "        signal_data = [base_signal + np.random.normal(0, 2) for _ in range(10)]\n",
    "        \n",
    "        test_data = {\n",
    "            'ra_stats': ra_stats,\n",
    "            'test_duration': 20,\n",
    "            'attacker_active': False,  # 正常情況無攻擊\n",
    "            'airplane_toggles': np.random.randint(3, 7),\n",
    "            'loop_number': i,\n",
    "            'test_type': 'normal',\n",
    "            'timestamps': timestamps,\n",
    "            'signal_data': signal_data\n",
    "        }\n",
    "        normal_data.append(test_data)\n",
    "    \n",
    "    print(f\"🔄 正在生成 {num_anomaly} 個異常樣本...\")\n",
    "    \n",
    "    # 生成異常行為數據\n",
    "    for i in range(num_anomaly):\n",
    "        # 異常情況：低成功率、不穩定信號、不規律時間間隔\n",
    "        \n",
    "        # 選擇異常類型\n",
    "        anomaly_type = np.random.choice(['attack', 'interference', 'hardware_failure'])\n",
    "        \n",
    "        if anomaly_type == 'attack':\n",
    "            # 攻擊場景：大量RA嘗試、較低成功率\n",
    "            ra_stats = {\n",
    "                'success_rate': np.clip(np.random.normal(60, 15), 30, 85),\n",
    "                'ra_initiated': np.random.randint(15, 25),\n",
    "                'ra_succeeded': lambda x: np.random.randint(max(1, int(x*0.4)), int(x*0.8)+1),\n",
    "                'failed_attempts': np.random.randint(5, 15)\n",
    "            }\n",
    "            base_signal = np.random.uniform(55, 75)  # 較高的信號（攻擊者信號）\n",
    "            signal_variation = 10\n",
    "            \n",
    "        elif anomaly_type == 'interference':\n",
    "            # 干擾場景：信號不穩定、成功率中等\n",
    "            ra_stats = {\n",
    "                'success_rate': np.clip(np.random.normal(70, 12), 45, 90),\n",
    "                'ra_initiated': np.random.randint(10, 20),\n",
    "                'ra_succeeded': lambda x: np.random.randint(max(1, int(x*0.5)), int(x*0.9)+1),\n",
    "                'failed_attempts': np.random.randint(2, 8)\n",
    "            }\n",
    "            base_signal = np.random.uniform(30, 50)  # 較低的信號（干擾影響）\n",
    "            signal_variation = 15\n",
    "            \n",
    "        else:  # hardware_failure\n",
    "            # 硬體故障場景：極低成功率、極不穩定\n",
    "            ra_stats = {\n",
    "                'success_rate': np.clip(np.random.normal(40, 20), 10, 70),\n",
    "                'ra_initiated': np.random.randint(20, 30),\n",
    "                'ra_succeeded': lambda x: np.random.randint(1, max(2, int(x*0.5))),\n",
    "                'failed_attempts': np.random.randint(10, 20)\n",
    "            }\n",
    "            base_signal = np.random.uniform(20, 40)  # 很低的信號（硬體問題）\n",
    "            signal_variation = 20\n",
    "        \n",
    "        ra_stats['ra_succeeded'] = ra_stats['ra_succeeded'](ra_stats['ra_initiated'])\n",
    "        ra_stats['success_rate'] = (ra_stats['ra_succeeded'] / ra_stats['ra_initiated']) * 100\n",
    "        \n",
    "        # 異常時間戳：不規律的間隔\n",
    "        timestamps = []\n",
    "        current_time = 0\n",
    "        for _ in range(np.random.randint(5, 15)):\n",
    "            # 更大的隨機變動，模擬不穩定\n",
    "            interval = np.random.exponential(2) + np.random.uniform(0.5, 4)\n",
    "            current_time += interval\n",
    "            timestamps.append(current_time)\n",
    "        \n",
    "        # 異常信號：不穩定且可能超出正常範圍\n",
    "        signal_data = [base_signal + np.random.normal(0, signal_variation) for _ in range(10)]\n",
    "        \n",
    "        test_data = {\n",
    "            'ra_stats': ra_stats,\n",
    "            'test_duration': 20,\n",
    "            'attacker_active': True,  # 異常情況假設有攻擊\n",
    "            'airplane_toggles': np.random.randint(8, 15),\n",
    "            'loop_number': i,\n",
    "            'test_type': 'anomaly',\n",
    "            'timestamps': timestamps,\n",
    "            'signal_data': signal_data,\n",
    "            'anomaly_type': anomaly_type\n",
    "        }\n",
    "        anomaly_data.append(test_data)\n",
    "    \n",
    "    print(f\"✅ 合成數據生成完成\")\n",
    "    print(f\"   正常樣本: {len(normal_data)}\")\n",
    "    print(f\"   異常樣本: {len(anomaly_data)}\")\n",
    "    \n",
    "    return normal_data, anomaly_data\n",
    "\n",
    "# 生成示例訓練數據\n",
    "normal_samples, anomaly_samples = generate_synthetic_training_data(100, 30)\n",
    "\n",
    "# 分析生成的數據\n",
    "print(\"\\\\n📊 數據分析:\")\n",
    "\n",
    "# 正常數據統計\n",
    "normal_success_rates = [sample['ra_stats']['success_rate'] for sample in normal_samples]\n",
    "print(f\"正常數據 - 平均成功率: {np.mean(normal_success_rates):.1f}% (±{np.std(normal_success_rates):.1f})\")\n",
    "\n",
    "# 異常數據統計\n",
    "anomaly_success_rates = [sample['ra_stats']['success_rate'] for sample in anomaly_samples]\n",
    "print(f\"異常數據 - 平均成功率: {np.mean(anomaly_success_rates):.1f}% (±{np.std(anomaly_success_rates):.1f})\")\n",
    "\n",
    "# 視覺化數據分佈\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(normal_success_rates, bins=20, alpha=0.7, label='正常', color='green')\n",
    "plt.hist(anomaly_success_rates, bins=20, alpha=0.7, label='異常', color='red')\n",
    "plt.xlabel('RA成功率 (%)')\n",
    "plt.ylabel('頻次')\n",
    "plt.title('成功率分佈比較')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "normal_ra_counts = [sample['ra_stats']['ra_initiated'] for sample in normal_samples]\n",
    "anomaly_ra_counts = [sample['ra_stats']['ra_initiated'] for sample in anomaly_samples]\n",
    "plt.hist(normal_ra_counts, bins=15, alpha=0.7, label='正常', color='green')\n",
    "plt.hist(anomaly_ra_counts, bins=15, alpha=0.7, label='異常', color='red')\n",
    "plt.xlabel('RA嘗試次數')\n",
    "plt.ylabel('頻次')\n",
    "plt.title('RA嘗試次數分佈比較')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec31ca08",
   "metadata": {},
   "source": [
    "## 5. 無監督學習模型訓練\n",
    "\n",
    "無監督學習算法只需要正常數據進行訓練，適用於缺乏標記異常數據的場景。我們將實作Isolation Forest、One-Class SVM和DBSCAN。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 為MLAnomalyDetector類別添加訓練方法\n",
    "def train_unsupervised(self, X: np.ndarray, feature_names: List[str] = None):\n",
    "    \"\"\"\n",
    "    無監督學習訓練（只使用正常數據）\n",
    "    \n",
    "    參數:\n",
    "        X: 訓練特徵矩陣 (n_samples, n_features)\n",
    "        feature_names: 特徵名稱列表\n",
    "    \"\"\"\n",
    "    if self.model_type in ['random_forest']:\n",
    "        print(f\"⚠️ {self.model_type} 是監督學習模型，需要標籤數據\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"🚀 開始訓練無監督模型: {self.model_type}\")\n",
    "    print(f\"訓練數據形狀: {X.shape}\")\n",
    "    \n",
    "    # 數據標準化\n",
    "    X_scaled = self.scaler.fit_transform(X)\n",
    "    print(f\"✅ 數據標準化完成\")\n",
    "    \n",
    "    # 訓練模型\n",
    "    if self.model_type == 'dbscan':\n",
    "        # DBSCAN 進行聚類，異常點標記為 -1\n",
    "        labels = self.model.fit_predict(X_scaled)\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_anomalies = sum(labels == -1)\n",
    "        print(f\"✅ DBSCAN 聚類完成\")\n",
    "        print(f\"   聚類數量: {n_clusters}\")\n",
    "        print(f\"   異常點數量: {n_anomalies} ({n_anomalies/len(labels)*100:.1f}%)\")\n",
    "    else:\n",
    "        # Isolation Forest 和 One-Class SVM\n",
    "        self.model.fit(X_scaled)\n",
    "        print(f\"✅ {self.model_type} 訓練完成\")\n",
    "    \n",
    "    self.is_trained = True\n",
    "    self.feature_names = feature_names or []\n",
    "    \n",
    "    # 在訓練數據上進行預測以評估模型\n",
    "    if self.model_type != 'dbscan':\n",
    "        predictions = self.model.predict(X_scaled)\n",
    "        n_anomalies = sum(predictions == -1)  # -1 表示異常\n",
    "        print(f\"訓練數據中檢測到的異常: {n_anomalies} ({n_anomalies/len(predictions)*100:.1f}%)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def predict_anomaly_batch(self, test_data_list: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    批量預測異常\n",
    "    \n",
    "    參數:\n",
    "        test_data_list: 測試數據列表\n",
    "        \n",
    "    返回:\n",
    "        預測結果列表\n",
    "    \"\"\"\n",
    "    if not self.is_trained:\n",
    "        return [{'error': 'Model not trained'} for _ in test_data_list]\n",
    "    \n",
    "    results = []\n",
    "    extractor = MLFeatureExtractor()\n",
    "    \n",
    "    for test_data in test_data_list:\n",
    "        try:\n",
    "            # 提取特徵\n",
    "            feature_vector = extractor.extract_comprehensive_features(test_data)\n",
    "            \n",
    "            # 確保特徵順序一致\n",
    "            if self.feature_names:\n",
    "                features = np.array([feature_vector.get(name, 0) for name in self.feature_names])\n",
    "            else:\n",
    "                sorted_keys = sorted(feature_vector.keys())\n",
    "                features = np.array([feature_vector[key] for key in sorted_keys])\n",
    "            \n",
    "            features = features.reshape(1, -1)\n",
    "            \n",
    "            # 標準化\n",
    "            features_scaled = self.scaler.transform(features)\n",
    "            \n",
    "            # 預測\n",
    "            if self.model_type in ['isolation_forest', 'one_class_svm']:\n",
    "                prediction = self.model.predict(features_scaled)[0]\n",
    "                \n",
    "                if hasattr(self.model, 'decision_function'):\n",
    "                    decision_score = self.model.decision_function(features_scaled)[0]\n",
    "                    confidence = abs(decision_score)\n",
    "                    anomaly_score = -decision_score if self.model_type == 'isolation_forest' else decision_score\n",
    "                else:\n",
    "                    confidence = 0.5\n",
    "                    anomaly_score = 0\n",
    "                \n",
    "                result = {\n",
    "                    'is_anomaly': prediction == -1,\n",
    "                    'confidence': confidence,\n",
    "                    'anomaly_score': anomaly_score,\n",
    "                    'prediction_value': prediction\n",
    "                }\n",
    "                \n",
    "            elif self.model_type == 'dbscan':\n",
    "                result = {\n",
    "                    'is_anomaly': False,\n",
    "                    'confidence': 0,\n",
    "                    'anomaly_score': 0,\n",
    "                    'error': 'DBSCAN cannot predict single samples'\n",
    "                }\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                'is_anomaly': False,\n",
    "                'confidence': 0,\n",
    "                'anomaly_score': 0,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 將方法添加到MLAnomalyDetector類別\n",
    "MLAnomalyDetector.train_unsupervised = train_unsupervised\n",
    "MLAnomalyDetector.predict_anomaly_batch = predict_anomaly_batch\n",
    "\n",
    "# 訓練無監督模型\n",
    "print(\"🔬 開始訓練無監督學習模型...\")\n",
    "\n",
    "# 提取正常數據的特徵\n",
    "extractor = MLFeatureExtractor()\n",
    "X_normal = []\n",
    "feature_names = None\n",
    "\n",
    "for data in normal_samples:\n",
    "    features = extractor.extract_comprehensive_features(data)\n",
    "    if feature_names is None:\n",
    "        feature_names = sorted(features.keys())\n",
    "    feature_vector = np.array([features[name] for name in feature_names])\n",
    "    X_normal.append(feature_vector)\n",
    "\n",
    "X_normal = np.array(X_normal)\n",
    "print(f\"正常數據特徵矩陣形狀: {X_normal.shape}\")\n",
    "\n",
    "# 訓練不同的無監督模型\n",
    "models = {\n",
    "    'isolation_forest': MLAnomalyDetector('isolation_forest'),\n",
    "    'one_class_svm': MLAnomalyDetector('one_class_svm'),\n",
    "    'dbscan': MLAnomalyDetector('dbscan')\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "for model_name, detector in models.items():\n",
    "    print(f\"\\\\n{'='*50}\")\n",
    "    print(f\"訓練模型: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    success = detector.train_unsupervised(X_normal, feature_names)\n",
    "    if success:\n",
    "        trained_models[model_name] = detector\n",
    "        print(f\"✅ {model_name} 訓練成功\")\n",
    "    else:\n",
    "        print(f\"❌ {model_name} 訓練失敗\")\n",
    "\n",
    "print(f\"\\\\n✅ 無監督學習訓練完成，成功訓練 {len(trained_models)} 個模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add5b769",
   "metadata": {},
   "source": [
    "## 6. 監督學習模型訓練\n",
    "\n",
    "監督學習需要標記的正常和異常數據，可以提供更精確的分類結果。我們將使用Random Forest進行監督學習訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 為MLAnomalyDetector類別添加監督學習訓練方法\n",
    "def train_supervised(self, X: np.ndarray, y: np.ndarray, feature_names: List[str] = None):\n",
    "    \"\"\"\n",
    "    監督學習訓練（使用標記的正常和異常數據）\n",
    "    \n",
    "    參數:\n",
    "        X: 特徵矩陣 (n_samples, n_features)\n",
    "        y: 標籤向量 (n_samples,) - 0表示正常，1表示異常\n",
    "        feature_names: 特徵名稱列表\n",
    "    \"\"\"\n",
    "    if self.model_type not in ['random_forest']:\n",
    "        print(f\"⚠️ {self.model_type} 不是監督學習模型\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"🚀 開始訓練監督學習模型: {self.model_type}\")\n",
    "    print(f\"訓練數據形狀: {X.shape}\")\n",
    "    print(f\"類別分佈 - 正常: {sum(y==0)}, 異常: {sum(y==1)}\")\n",
    "    \n",
    "    # 數據標準化\n",
    "    X_scaled = self.scaler.fit_transform(X)\n",
    "    print(f\"✅ 數據標準化完成\")\n",
    "    \n",
    "    # 分割訓練/測試集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    print(f\"數據分割 - 訓練集: {X_train.shape[0]}, 測試集: {X_test.shape[0]}\")\n",
    "    \n",
    "    # 訓練模型\n",
    "    self.model.fit(X_train, y_train)\n",
    "    print(f\"✅ {self.model_type} 訓練完成\")\n",
    "    \n",
    "    # 評估模型\n",
    "    y_pred = self.model.predict(X_test)\n",
    "    y_pred_proba = self.model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(f\"\\\\n📊 模型評估結果:\")\n",
    "    print(\"分類報告:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['正常', '異常']))\n",
    "    \n",
    "    # AUC分數\n",
    "    if len(np.unique(y)) == 2:\n",
    "        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"AUC分數: {auc_score:.3f}\")\n",
    "    \n",
    "    # 混淆矩陣\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\\\n混淆矩陣:\")\n",
    "    print(f\"     預測\")\n",
    "    print(f\"實際  正常  異常\")\n",
    "    print(f\"正常  {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "    print(f\"異常  {cm[1,0]:4d}  {cm[1,1]:4d}\")\n",
    "    \n",
    "    self.is_trained = True\n",
    "    self.feature_names = feature_names or []\n",
    "    \n",
    "    # 特徵重要性分析\n",
    "    if hasattr(self.model, 'feature_importances_') and feature_names:\n",
    "        self._analyze_feature_importance()\n",
    "    \n",
    "    return True, {\n",
    "        'auc_score': auc_score if len(np.unique(y)) == 2 else None,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': classification_report(y_test, y_pred, output_dict=True)\n",
    "    }\n",
    "\n",
    "def _analyze_feature_importance(self):\n",
    "    \"\"\"分析特徵重要性\"\"\"\n",
    "    if not hasattr(self.model, 'feature_importances_'):\n",
    "        return\n",
    "    \n",
    "    importances = self.model.feature_importances_\n",
    "    feature_importance = list(zip(self.feature_names, importances))\n",
    "    feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\\\n🔍 前10個最重要的特徵:\")\n",
    "    for i, (feature, importance) in enumerate(feature_importance[:10]):\n",
    "        print(f\"  {i+1:2d}. {feature:<25}: {importance:.4f}\")\n",
    "    \n",
    "    # 視覺化特徵重要性\n",
    "    top_features = feature_importance[:15]  # 取前15個特徵\n",
    "    features, importances = zip(*top_features)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(features)), importances)\n",
    "    plt.yticks(range(len(features)), features)\n",
    "    plt.xlabel('特徵重要性')\n",
    "    plt.title('Random Forest 特徵重要性排名')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 將方法添加到MLAnomalyDetector類別\n",
    "MLAnomalyDetector.train_supervised = train_supervised\n",
    "MLAnomalyDetector._analyze_feature_importance = _analyze_feature_importance\n",
    "\n",
    "# 準備監督學習數據\n",
    "print(\"📚 準備監督學習數據...\")\n",
    "\n",
    "# 提取所有數據的特徵（正常 + 異常）\n",
    "all_data = normal_samples + anomaly_samples\n",
    "X_all = []\n",
    "y_all = []\n",
    "\n",
    "for i, data in enumerate(all_data):\n",
    "    features = extractor.extract_comprehensive_features(data)\n",
    "    feature_vector = np.array([features[name] for name in feature_names])\n",
    "    X_all.append(feature_vector)\n",
    "    \n",
    "    # 標籤：正常=0，異常=1\n",
    "    if i < len(normal_samples):\n",
    "        y_all.append(0)  # 正常\n",
    "    else:\n",
    "        y_all.append(1)  # 異常\n",
    "\n",
    "X_all = np.array(X_all)\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "print(f\"完整數據集形狀: {X_all.shape}\")\n",
    "print(f\"標籤分佈 - 正常: {sum(y_all==0)}, 異常: {sum(y_all==1)}\")\n",
    "\n",
    "# 訓練監督學習模型\n",
    "print(f\"\\\\n{'='*50}\")\n",
    "print(f\"訓練監督學習模型: Random Forest\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "rf_detector = MLAnomalyDetector('random_forest')\n",
    "success, metrics = rf_detector.train_supervised(X_all, y_all, feature_names)\n",
    "\n",
    "if success:\n",
    "    trained_models['random_forest'] = rf_detector\n",
    "    print(f\"✅ Random Forest 訓練成功\")\n",
    "else:\n",
    "    print(f\"❌ Random Forest 訓練失敗\")\n",
    "\n",
    "print(f\"\\\\n✅ 監督學習訓練完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf5680",
   "metadata": {},
   "source": [
    "## 7. 模型驗證與評估\n",
    "\n",
    "評估訓練好的模型性能，使用測試數據進行預測並分析各模型的檢測能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成測試數據\n",
    "print(\"🧪 生成測試數據...\")\n",
    "test_normal, test_anomaly = generate_synthetic_training_data(20, 10)\n",
    "test_data = test_normal + test_anomaly\n",
    "test_labels = [0] * len(test_normal) + [1] * len(test_anomaly)\n",
    "\n",
    "print(f\"測試數據 - 正常: {len(test_normal)}, 異常: {len(test_anomaly)}\")\n",
    "\n",
    "# 評估所有訓練好的模型\n",
    "def evaluate_model(detector, test_data, test_labels, model_name):\n",
    "    \"\"\"評估單個模型的性能\"\"\"\n",
    "    print(f\"\\\\n🔍 評估模型: {model_name}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    if not detector.is_trained:\n",
    "        print(\"❌ 模型未訓練\")\n",
    "        return None\n",
    "    \n",
    "    # 批量預測\n",
    "    predictions = detector.predict_anomaly_batch(test_data)\n",
    "    \n",
    "    # 提取預測結果\n",
    "    y_pred = []\n",
    "    confidences = []\n",
    "    \n",
    "    for pred in predictions:\n",
    "        if 'error' in pred:\n",
    "            y_pred.append(0)  # 默認為正常\n",
    "            confidences.append(0)\n",
    "        else:\n",
    "            y_pred.append(1 if pred['is_anomaly'] else 0)\n",
    "            confidences.append(pred.get('confidence', 0))\n",
    "    \n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(test_labels)\n",
    "    \n",
    "    # 計算評估指標\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # 混淆矩陣\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n",
    "    \n",
    "    # 計算其他指標\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    \n",
    "    print(f\"準確率 (Accuracy):     {accuracy:.3f}\")\n",
    "    print(f\"精確率 (Precision):    {precision:.3f}\")\n",
    "    print(f\"召回率 (Recall):       {recall:.3f}\")\n",
    "    print(f\"F1分數:                {f1:.3f}\")\n",
    "    print(f\"特異性 (Specificity):  {specificity:.3f}\")\n",
    "    print(f\"假陽性率 (FPR):        {false_positive_rate:.3f}\")\n",
    "    print(f\"假陰性率 (FNR):        {false_negative_rate:.3f}\")\n",
    "    \n",
    "    print(f\"\\\\n混淆矩陣:\")\n",
    "    print(f\"     預測\")\n",
    "    print(f\"實際  正常  異常\")\n",
    "    print(f\"正常  {tn:4d}  {fp:4d}\")\n",
    "    print(f\"異常  {fn:4d}  {tp:4d}\")\n",
    "    \n",
    "    # 返回評估結果\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'specificity': specificity,\n",
    "        'fpr': false_positive_rate,\n",
    "        'fnr': false_negative_rate,\n",
    "        'confusion_matrix': cm,\n",
    "        'predictions': y_pred,\n",
    "        'confidences': confidences\n",
    "    }\n",
    "\n",
    "# 評估所有模型\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_name, detector in trained_models.items():\n",
    "    result = evaluate_model(detector, test_data, test_labels, model_name)\n",
    "    if result:\n",
    "        evaluation_results[model_name] = result\n",
    "\n",
    "# 比較模型性能\n",
    "print(f\"\\\\n{'='*60}\")\n",
    "print(f\"                    模型性能比較\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if evaluation_results:\n",
    "    # 創建比較表格\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'specificity']\n",
    "    \n",
    "    print(f\"{'模型':<20}\", end='')\n",
    "    for metric in metrics:\n",
    "        print(f\"{metric.upper():<12}\", end='')\n",
    "    print()\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for model_name, result in evaluation_results.items():\n",
    "        print(f\"{model_name:<20}\", end='')\n",
    "        for metric in metrics:\n",
    "            print(f\"{result[metric]:<12.3f}\", end='')\n",
    "        print()\n",
    "    \n",
    "    # 視覺化比較\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 性能指標比較\n",
    "    plt.subplot(2, 3, 1)\n",
    "    models = list(evaluation_results.keys())\n",
    "    accuracies = [evaluation_results[m]['accuracy'] for m in models]\n",
    "    plt.bar(models, accuracies, color='skyblue')\n",
    "    plt.title('準確率比較')\n",
    "    plt.ylabel('準確率')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(2, 3, 2)\n",
    "    precisions = [evaluation_results[m]['precision'] for m in models]\n",
    "    plt.bar(models, precisions, color='lightgreen')\n",
    "    plt.title('精確率比較')\n",
    "    plt.ylabel('精確率')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(2, 3, 3)\n",
    "    recalls = [evaluation_results[m]['recall'] for m in models]\n",
    "    plt.bar(models, recalls, color='salmon')\n",
    "    plt.title('召回率比較')\n",
    "    plt.ylabel('召回率')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(2, 3, 4)\n",
    "    f1_scores = [evaluation_results[m]['f1_score'] for m in models]\n",
    "    plt.bar(models, f1_scores, color='gold')\n",
    "    plt.title('F1分數比較')\n",
    "    plt.ylabel('F1分數')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # ROC曲線（僅限監督學習模型）\n",
    "    plt.subplot(2, 3, 5)\n",
    "    for model_name, result in evaluation_results.items():\n",
    "        if model_name == 'random_forest':\n",
    "            # 為監督學習模型繪製ROC曲線\n",
    "            detector = trained_models[model_name]\n",
    "            # 重新計算概率預測\n",
    "            X_test = []\n",
    "            for data in test_data:\n",
    "                features = extractor.extract_comprehensive_features(data)\n",
    "                feature_vector = np.array([features[name] for name in feature_names])\n",
    "                X_test.append(feature_vector)\n",
    "            \n",
    "            X_test = np.array(X_test)\n",
    "            X_test_scaled = detector.scaler.transform(X_test)\n",
    "            y_prob = detector.model.predict_proba(X_test_scaled)[:, 1]\n",
    "            \n",
    "            fpr, tpr, _ = roc_curve(test_labels, y_prob)\n",
    "            auc = roc_auc_score(test_labels, y_prob)\n",
    "            plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='隨機分類器')\n",
    "    plt.xlabel('假陽性率')\n",
    "    plt.ylabel('真陽性率')\n",
    "    plt.title('ROC曲線')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 信心度分佈\n",
    "    plt.subplot(2, 3, 6)\n",
    "    for model_name, result in evaluation_results.items():\n",
    "        if model_name != 'dbscan':  # DBSCAN沒有信心度\n",
    "            confidences = result['confidences']\n",
    "            plt.hist(confidences, bins=20, alpha=0.5, label=model_name)\n",
    "    \n",
    "    plt.xlabel('預測信心度')\n",
    "    plt.ylabel('頻次')\n",
    "    plt.title('預測信心度分佈')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 推薦最佳模型\n",
    "    print(f\"\\\\n🏆 模型推薦:\")\n",
    "    best_f1_model = max(evaluation_results.items(), key=lambda x: x[1]['f1_score'])\n",
    "    best_accuracy_model = max(evaluation_results.items(), key=lambda x: x[1]['accuracy'])\n",
    "    \n",
    "    print(f\"最佳F1分數: {best_f1_model[0]} (F1 = {best_f1_model[1]['f1_score']:.3f})\")\n",
    "    print(f\"最佳準確率: {best_accuracy_model[0]} (Accuracy = {best_accuracy_model[1]['accuracy']:.3f})\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 沒有可評估的模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db070a",
   "metadata": {},
   "source": [
    "## 8. 實時異常偵測實作\n",
    "\n",
    "建立RealTimeAnomalyDetector類別，實現連續監控、閾值設定、警報機制等實時偵測功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeAnomalyDetector:\n",
    "    \"\"\"\n",
    "    實時異常偵測系統 - 整合ML模型到現有的測試框架\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, detector: MLAnomalyDetector = None, alert_callback: Callable = None):\n",
    "        \"\"\"\n",
    "        初始化實時異常偵測器\n",
    "        \n",
    "        參數:\n",
    "            detector: 訓練好的MLAnomalyDetector\n",
    "            alert_callback: 異常警報回調函數\n",
    "        \"\"\"\n",
    "        self.detector = detector\n",
    "        self.feature_extractor = MLFeatureExtractor()\n",
    "        self.alert_callback = alert_callback\n",
    "        self.is_monitoring = False\n",
    "        self.data_queue = queue.Queue()\n",
    "        self.monitoring_thread = None\n",
    "        \n",
    "        # 異常偵測參數\n",
    "        self.alert_threshold = 0.7\n",
    "        self.consecutive_anomalies_threshold = 3\n",
    "        self.time_window_minutes = 5\n",
    "        \n",
    "        # 統計資料\n",
    "        self.anomaly_history = []\n",
    "        self.total_predictions = 0\n",
    "        self.total_anomalies = 0\n",
    "        self.consecutive_anomalies = 0\n",
    "        \n",
    "        print(f\"✅ RealTimeAnomalyDetector 初始化完成\")\n",
    "    \n",
    "    def set_detector(self, detector: MLAnomalyDetector):\n",
    "        \"\"\"設置ML偵測器\"\"\"\n",
    "        self.detector = detector\n",
    "        print(f\"✅ ML偵測器已設置: {detector.model_type}\")\n",
    "    \n",
    "    def start_monitoring(self):\n",
    "        \"\"\"開始實時監控\"\"\"\n",
    "        if self.is_monitoring:\n",
    "            print(\"⚠️ 監控已經在運行中\")\n",
    "            return False\n",
    "        \n",
    "        if not self.detector or not self.detector.is_trained:\n",
    "            print(\"❌ 沒有可用的訓練模型\")\n",
    "            return False\n",
    "        \n",
    "        self.is_monitoring = True\n",
    "        self.monitoring_thread = threading.Thread(target=self._monitoring_loop)\n",
    "        self.monitoring_thread.daemon = True\n",
    "        self.monitoring_thread.start()\n",
    "        \n",
    "        print(f\"🚀 實時異常監控已啟動 (模型: {self.detector.model_type})\")\n",
    "        return True\n",
    "    \n",
    "    def stop_monitoring(self):\n",
    "        \"\"\"停止實時監控\"\"\"\n",
    "        self.is_monitoring = False\n",
    "        if self.monitoring_thread:\n",
    "            self.monitoring_thread.join(timeout=5)\n",
    "        \n",
    "        print(f\"⏹️ 實時異常監控已停止\")\n",
    "    \n",
    "    def feed_data(self, test_data: Dict):\n",
    "        \"\"\"餵入新的測試數據\"\"\"\n",
    "        if not self.is_monitoring:\n",
    "            return\n",
    "        \n",
    "        # 添加時間戳\n",
    "        test_data['timestamp'] = datetime.now().isoformat()\n",
    "        \n",
    "        try:\n",
    "            self.data_queue.put(test_data, timeout=1)\n",
    "        except queue.Full:\n",
    "            print(\"⚠️ 數據隊列已滿，清理舊數據\")\n",
    "            # 清空一半的舊數據\n",
    "            for _ in range(self.data_queue.qsize() // 2):\n",
    "                try:\n",
    "                    self.data_queue.get_nowait()\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "            self.data_queue.put(test_data)\n",
    "    \n",
    "    def _monitoring_loop(self):\n",
    "        \"\"\"監控主循環\"\"\"\n",
    "        print(f\"🔄 監控主循環已啟動\")\n",
    "        \n",
    "        while self.is_monitoring:\n",
    "            try:\n",
    "                # 從隊列獲取數據\n",
    "                test_data = self.data_queue.get(timeout=1)\n",
    "                \n",
    "                # 進行異常偵測\n",
    "                predictions = self.detector.predict_anomaly_batch([test_data])\n",
    "                \n",
    "                if predictions and not predictions[0].get('error'):\n",
    "                    result = predictions[0]\n",
    "                    \n",
    "                    # 更新統計\n",
    "                    self.total_predictions += 1\n",
    "                    \n",
    "                    if result.get('is_anomaly', False):\n",
    "                        self.total_anomalies += 1\n",
    "                        self.consecutive_anomalies += 1\n",
    "                        \n",
    "                        # 記錄異常\n",
    "                        anomaly_record = {\\n                            'timestamp': test_data.get('timestamp'),\\n                            'confidence': result.get('confidence', 0),\\n                            'anomaly_score': result.get('anomaly_score', 0),\\n                            'test_data': test_data,\\n                            'result': result,\\n                            'consecutive_count': self.consecutive_anomalies\\n                        }\\n                        self.anomaly_history.append(anomaly_record)\\n                        \\n                        # 檢查是否需要發出警報\\n                        if (result.get('confidence', 0) >= self.alert_threshold or \\n                            self.consecutive_anomalies >= self.consecutive_anomalies_threshold):\\n                            self._trigger_alert(anomaly_record)\\n                        \\n                        print(f\\\"🚨 異常偵測 - 信心度: {result.get('confidence', 0):.3f}, 連續次數: {self.consecutive_anomalies}\\\")\\n                        \\n                    else:\\n                        self.consecutive_anomalies = 0  # 重置連續異常計數\\n                \\n                # 清理舊的異常記錄\\n                self._cleanup_old_records()\\n                \\n            except queue.Empty:\\n                continue\\n            except Exception as e:\\n                print(f\\\"❌ 監控循環錯誤: {e}\\\")\\n    \\n    def _trigger_alert(self, anomaly_record: Dict):\\n        \\\"\\\"\\\"觸發異常警報\\\"\\\"\\\"\\n        alert_message = f\\\"⚠️ 高信心度異常偵測警報!\\\"\\n        alert_details = {\\n            'timestamp': anomaly_record['timestamp'],\\n            'confidence': anomaly_record['confidence'],\\n            'anomaly_score': anomaly_record['anomaly_score'],\\n            'consecutive_count': anomaly_record['consecutive_count'],\\n            'model_type': self.detector.model_type\\n        }\\n        \\n        print(f\\\"🚨 {alert_message}\\\")\\n        print(f\\\"🚨 詳細資訊: {alert_details}\\\")\\n        \\n        # 呼叫自定義警報回調\\n        if self.alert_callback:\\n            try:\\n                self.alert_callback(alert_message, alert_details, anomaly_record)\\n            except Exception as e:\\n                print(f\\\"❌ 警報回調失敗: {e}\\\")\\n    \\n    def _cleanup_old_records(self):\\n        \\\"\\\"\\\"清理超過時間窗口的舊記錄\\\"\\\"\\\"\\n        cutoff_time = datetime.now() - timedelta(minutes=self.time_window_minutes)\\n        \\n        self.anomaly_history = [\\n            record for record in self.anomaly_history\\n            if datetime.fromisoformat(record['timestamp']) > cutoff_time\\n        ]\\n    \\n    def get_statistics(self) -> Dict:\\n        \\\"\\\"\\\"獲取實時統計資料\\\"\\\"\\\"\\n        recent_anomalies = len([\\n            r for r in self.anomaly_history\\n            if datetime.fromisoformat(r['timestamp']) > datetime.now() - timedelta(minutes=self.time_window_minutes)\\n        ])\\n        \\n        anomaly_rate = (self.total_anomalies / max(self.total_predictions, 1)) * 100\\n        \\n        return {\\n            'total_predictions': self.total_predictions,\\n            'total_anomalies': self.total_anomalies,\\n            'anomaly_rate': anomaly_rate,\\n            'recent_anomalies': recent_anomalies,\\n            'consecutive_anomalies': self.consecutive_anomalies,\\n            'is_monitoring': self.is_monitoring,\\n            'queue_size': self.data_queue.qsize(),\\n            'model_type': self.detector.model_type if self.detector else None\\n        }\\n    \\n    def set_alert_threshold(self, threshold: float):\\n        \\\"\\\"\\\"設定警報閾值\\\"\\\"\\\"\\n        self.alert_threshold = threshold\\n        print(f\\\"🔧 警報閾值已設定為 {threshold}\\\")\\n    \\n    def set_consecutive_threshold(self, count: int):\\n        \\\"\\\"\\\"設定連續異常警報閾值\\\"\\\"\\\"\\n        self.consecutive_anomalies_threshold = count\\n        print(f\\\"🔧 連續異常閾值已設定為 {count}\\\")\\n\\n# 測試實時異常偵測系統\\nprint(\\\"\\\\n🧪 測試實時異常偵測系統...\\\")\\n\\n# 定義警報回調函數\\ndef alert_callback(message: str, details: Dict, record: Dict):\\n    print(f\\\"📢 警報回調: {message}\\\")\\n    print(f\\\"📢 模型類型: {details['model_type']}\\\")\\n    print(f\\\"📢 異常分數: {details['anomaly_score']:.3f}\\\")\\n\\n# 選擇最佳模型進行實時偵測\\nif evaluation_results:\\n    best_model_name = max(evaluation_results.items(), key=lambda x: x[1]['f1_score'])[0]\\n    best_detector = trained_models[best_model_name]\\n    \\n    print(f\\\"選擇最佳模型進行實時偵測: {best_model_name}\\\")\\n    \\n    # 創建實時偵測器\\n    rt_detector = RealTimeAnomalyDetector(best_detector, alert_callback)\\n    rt_detector.set_alert_threshold(0.6)  # 較低的閾值以增加敏感度\\n    rt_detector.set_consecutive_threshold(2)\\n    \\n    # 啟動監控\\n    rt_detector.start_monitoring()\\n    \\n    # 模擬餵入測試數據\\n    print(\\\"\\\\n🔄 模擬實時數據流...\\\")\\n    \\n    # 餵入一些正常數據\\n    for i in range(5):\\n        normal_data = test_normal[i % len(test_normal)]\\n        rt_detector.feed_data(normal_data)\\n        time.sleep(0.1)\\n    \\n    # 餵入一些異常數據\\n    for i in range(3):\\n        anomaly_data = test_anomaly[i % len(test_anomaly)]\\n        rt_detector.feed_data(anomaly_data)\\n        time.sleep(0.1)\\n    \\n    # 等待處理完成\\n    time.sleep(2)\\n    \\n    # 獲取統計資料\\n    stats = rt_detector.get_statistics()\\n    print(f\\\"\\\\n📊 實時偵測統計:\\\")\\n    for key, value in stats.items():\\n        print(f\\\"  {key}: {value}\\\")\\n    \\n    # 停止監控\\n    rt_detector.stop_monitoring()\\n    \\nelse:\\n    print(\\\"❌ 沒有可用的訓練模型進行實時偵測測試\\\")\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b836a2ea",
   "metadata": {},
   "source": [
    "## 9. 模型保存與載入\n",
    "\n",
    "實作模型序列化功能，允許保存訓練好的模型並在後續測試中重複使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ab5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 為MLAnomalyDetector類別添加保存和載入方法\\ndef save_model(self, filepath: str):\\n    \\\"\\\"\\\"儲存訓練好的模型\\\"\\\"\\\"\\n    if not self.is_trained:\\n        print(\\\"⚠️ 沒有已訓練的模型可以保存\\\")\\n        return False\\n    \\n    model_data = {\\n        'model': self.model,\\n        'scaler': self.scaler,\\n        'model_type': self.model_type,\\n        'feature_names': self.feature_names,\\n        'threshold': self.threshold,\\n        'timestamp': datetime.now().isoformat(),\\n        'is_trained': self.is_trained\\n    }\\n    \\n    try:\\n        joblib.dump(model_data, filepath)\\n        print(f\\\"✅ 模型已保存到 {filepath}\\\")\\n        return True\\n    except Exception as e:\\n        print(f\\\"❌ 模型保存失敗: {e}\\\")\\n        return False\\n\\ndef load_model(self, filepath: str):\\n    \\\"\\\"\\\"載入訓練好的模型\\\"\\\"\\\"\\n    try:\\n        model_data = joblib.load(filepath)\\n        \\n        self.model = model_data['model']\\n        self.scaler = model_data['scaler']\\n        self.model_type = model_data['model_type']\\n        self.feature_names = model_data.get('feature_names', [])\\n        self.threshold = model_data.get('threshold', 0.5)\\n        self.is_trained = model_data.get('is_trained', True)\\n        \\n        print(f\\\"✅ 模型已從 {filepath} 載入\\\")\\n        print(f\\\"   模型類型: {self.model_type}\\\")\\n        print(f\\\"   特徵數量: {len(self.feature_names)}\\\")\\n        print(f\\\"   訓練時間: {model_data.get('timestamp', 'Unknown')}\\\")\\n        return True\\n        \\n    except Exception as e:\\n        print(f\\\"❌ 模型載入失敗: {e}\\\")\\n        return False\\n\\n# 將方法添加到MLAnomalyDetector類別\\nMLAnomalyDetector.save_model = save_model\\nMLAnomalyDetector.load_model = load_model\\n\\n# 保存所有訓練好的模型\\nprint(\\\"💾 保存訓練好的模型...\\\")\\n\\nmodel_save_dir = \\\"/home/ksmo/ml_models\\\"\\nimport os\\nos.makedirs(model_save_dir, exist_ok=True)\\n\\nsaved_models = {}\\n\\nfor model_name, detector in trained_models.items():\\n    filepath = os.path.join(model_save_dir, f\\\"5g_anomaly_{model_name}.joblib\\\")\\n    success = detector.save_model(filepath)\\n    if success:\\n        saved_models[model_name] = filepath\\n\\nprint(f\\\"\\\\n✅ 成功保存 {len(saved_models)} 個模型:\\\")\\nfor model_name, filepath in saved_models.items():\\n    print(f\\\"  {model_name}: {filepath}\\\")\\n\\n# 測試模型載入\\nprint(f\\\"\\\\n🔄 測試模型載入功能...\\\")\\n\\nif saved_models:\\n    # 選擇一個模型進行載入測試\\n    test_model_name = list(saved_models.keys())[0]\\n    test_filepath = saved_models[test_model_name]\\n    \\n    # 創建新的偵測器並載入模型\\n    new_detector = MLAnomalyDetector(test_model_name)\\n    success = new_detector.load_model(test_filepath)\\n    \\n    if success:\\n        print(f\\\"✅ 模型載入測試成功\\\")\\n        \\n        # 驗證載入的模型功能\\n        test_sample = test_data[0]\\n        predictions = new_detector.predict_anomaly_batch([test_sample])\\n        \\n        if predictions and not predictions[0].get('error'):\\n            result = predictions[0]\\n            print(f\\\"   預測測試: 異常={result['is_anomaly']}, 信心度={result.get('confidence', 0):.3f}\\\")\\n        else:\\n            print(f\\\"   ⚠️ 預測測試失敗\\\")\\n    else:\\n        print(f\\\"❌ 模型載入測試失敗\\\")\\n\\n# 創建模型資訊摘要\\nmodel_summary = {\\n    'training_date': datetime.now().isoformat(),\\n    'models_trained': list(trained_models.keys()),\\n    'evaluation_results': evaluation_results,\\n    'best_model': {\\n        'name': max(evaluation_results.items(), key=lambda x: x[1]['f1_score'])[0] if evaluation_results else None,\\n        'f1_score': max(evaluation_results.items(), key=lambda x: x[1]['f1_score'])[1]['f1_score'] if evaluation_results else None\\n    },\\n    'training_data_summary': {\\n        'normal_samples': len(normal_samples),\\n        'anomaly_samples': len(anomaly_samples),\\n        'features_count': len(feature_names),\\n        'feature_names': feature_names\\n    }\\n}\\n\\n# 保存訓練摘要\\nsummary_filepath = os.path.join(model_save_dir, \\\"training_summary.json\\\")\\nwith open(summary_filepath, 'w', encoding='utf-8') as f:\\n    json.dump(model_summary, f, indent=2, ensure_ascii=False)\\n\\nprint(f\\\"\\\\n📋 訓練摘要已保存到: {summary_filepath}\\\")\\n\\n# 顯示保存的檔案\\nprint(f\\\"\\\\n📁 保存的檔案列表:\\\")\\nfor filename in os.listdir(model_save_dir):\\n    filepath = os.path.join(model_save_dir, filename)\\n    file_size = os.path.getsize(filepath) / 1024  # KB\\n    print(f\\\"  {filename:<35} ({file_size:.1f} KB)\\\")\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c25bc4",
   "metadata": {},
   "source": [
    "## 10. 整合到測試系統中\n",
    "\n",
    "將ML異常偵測功能整合到TestSelector系統中，包含配置介面、統計報告和警報處理機制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9613edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演示如何在TestSelector中使用ML異常偵測\\n\\nclass TestSelectorMLIntegration:\\n    \\\"\\\"\\\"\\n    演示TestSelector與ML異常偵測的整合\\n    \\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.ml_enabled = False\\n        self.ml_detector = None\\n        self.real_time_detector = None\\n        \\n    def enable_ml_detection(self, model_path: str = None, model_type: str = 'isolation_forest'):\\n        \\\"\\\"\\\"啟用ML異常偵測\\\"\\\"\\\"\\n        try:\\n            self.ml_detector = MLAnomalyDetector(model_type=model_type)\\n            \\n            if model_path and os.path.exists(model_path):\\n                success = self.ml_detector.load_model(model_path)\\n                if success:\\n                    print(f\\\"✅ 已載入預訓練模型: {model_path}\\\")\\n                else:\\n                    print(f\\\"❌ 模型載入失敗，將使用未訓練的模型\\\")\\n            else:\\n                print(f\\\"⚠️ 未指定模型路徑或檔案不存在，模型需要訓練\\\")\\n            \\n            # 初始化實時偵測器\\n            self.real_time_detector = RealTimeAnomalyDetector(\\n                detector=self.ml_detector,\\n                alert_callback=self._handle_ml_alert\\n            )\\n            \\n            self.ml_enabled = True\\n            print(f\\\"✅ ML異常偵測已啟用 (模型: {model_type})\\\")\\n            \\n        except Exception as e:\\n            print(f\\\"❌ ML偵測啟用失敗: {e}\\\")\\n            self.ml_enabled = False\\n    \\n    def _handle_ml_alert(self, message: str, details: Dict, record: Dict):\\n        \\\"\\\"\\\"處理ML異常警報\\\"\\\"\\\"\\n        print(f\\\"🚨 ML異常警報: {message}\\\")\\n        print(f\\\"🚨 信心度: {details['confidence']:.3f}\\\")\\n        print(f\\\"🚨 異常分數: {details['anomaly_score']:.3f}\\\")\\n        print(f\\\"🚨 連續異常次數: {details['consecutive_count']}\\\")\\n        \\n        # 這裡可以添加自動回應邏輯:\\n        # 1. 記錄到專用日誌檔案\\n        # 2. 發送緊急通知給管理員\\n        # 3. 觸發額外的診斷程序\\n        # 4. 在嚴重情況下自動停止測試\\n    \\n    def enhanced_analyze_ra_procedure(self, ra_stats: Dict, loop_number: int, test_type: str = \\\"standard\\\") -> Dict:\\n        \\\"\\\"\\\"增強的RA程序分析（整合ML偵測）\\\"\\\"\\\"\\n        \\n        # 原始RA分析\\n        enhanced_stats = ra_stats.copy()\\n        \\n        # 如果ML偵測已啟用且模型已訓練\\n        if self.ml_enabled and self.ml_detector and self.ml_detector.is_trained:\\n            print(f\\\"🔍 執行ML分析 - 循環 {loop_number} ({test_type})\\\")\\n            \\n            # 根據測試類型調整預期行為\\n            if test_type == \\\"cots_only\\\":\\n                base_signal = 45\\n                signal_variation = 3\\n                expected_toggles = 3\\n            else:\\n                base_signal = 55\\n                signal_variation = 8\\n                expected_toggles = 5\\n            \\n            # 準備ML輸入數據\\n            current_time = time.time()\\n            test_data = {\\n                'ra_stats': ra_stats,\\n                'test_duration': 20,\\n                'attacker_active': test_type != \\\"cots_only\\\",\\n                'airplane_toggles': expected_toggles,\\n                'loop_number': loop_number,\\n                'test_type': test_type,\\n                'timestamps': [current_time - (20 - i*2) for i in range(min(ra_stats.get('ra_initiated', 5), 10))],\\n                'signal_data': [base_signal + (i * signal_variation / 10) + \\n                              np.random.normal(0, 2 if test_type == \\\"cots_only\\\" else 5) \\n                              for i in range(10)]\\n            }\\n            \\n            # 執行ML異常偵測\\n            try:\\n                predictions = self.ml_detector.predict_anomaly_batch([test_data])\\n                \\n                if predictions and not predictions[0].get('error'):\\n                    ml_result = predictions[0]\\n                    \\n                    # 針對COTS only模式調整判斷邏輯\\n                    if test_type == \\\"cots_only\\\":\\n                        adjusted_threshold = 0.8\\n                        is_anomaly_adjusted = (ml_result.get('is_anomaly', False) and \\n                                              ml_result.get('confidence', 0) > adjusted_threshold)\\n                        \\n                        if ml_result.get('is_anomaly', False) and not is_anomaly_adjusted:\\n                            ml_result['is_anomaly'] = False\\n                            ml_result['confidence'] = ml_result.get('confidence', 0) * 0.5\\n                    \\n                    # 將ML結果整合到RA統計中\\n                    enhanced_stats.update({\\n                        'ml_anomaly_detected': ml_result.get('is_anomaly', False),\\n                        'ml_confidence': ml_result.get('confidence', 0),\\n                        'ml_anomaly_score': ml_result.get('anomaly_score', 0),\\n                        'ml_model_type': self.ml_detector.model_type,\\n                        'ml_test_type': test_type\\n                    })\\n                    \\n                    # 餵入實時偵測器\\n                    if self.real_time_detector and self.real_time_detector.is_monitoring:\\n                        self.real_time_detector.feed_data(test_data)\\n                    \\n                    # 顯示ML分析結果\\n                    if ml_result.get('is_anomaly', False):\\n                        print(f\\\"🔍 ML分析: 循環 {loop_number} 檢測到異常 ({test_type})!\\\")\\n                        print(f\\\"🔍 信心度: {ml_result.get('confidence', 0):.3f}\\\")\\n                        if test_type == \\\"cots_only\\\":\\n                            print(f\\\"⚠️ 注意: COTS-only模式下檢測到異常（不尋常）\\\")\\n                    else:\\n                        print(f\\\"✅ ML分析: 循環 {loop_number} 行為正常 ({test_type})\\\")\\n                        \\n                else:\\n                    print(f\\\"❌ ML分析失敗: {predictions[0].get('error', 'Unknown error')}\\\")\\n                    \\n            except Exception as e:\\n                print(f\\\"❌ ML分析異常: {e}\\\")\\n                enhanced_stats.update({\\n                    'ml_anomaly_detected': False,\\n                    'ml_confidence': 0,\\n                    'ml_error': str(e)\\n                })\\n        else:\\n            if self.ml_enabled and self.ml_detector and not self.ml_detector.is_trained:\\n                print(f\\\"ℹ️ ML已啟用但模型未訓練，跳過ML分析\\\")\\n        \\n        return enhanced_stats\\n    \\n    def get_ml_statistics(self) -> Dict:\\n        \\\"\\\"\\\"獲取ML統計資料\\\"\\\"\\\"\\n        if self.real_time_detector:\\n            return self.real_time_detector.get_statistics()\\n        return {}\\n    \\n    def configure_ml_parameters(self):\\n        \\\"\\\"\\\"配置ML參數\\\"\\\"\\\"\\n        if not self.ml_enabled:\\n            print(\\\"❌ ML偵測未啟用\\\")\\n            return\\n        \\n        print(\\\"\\\\n🔧 ML偵測參數配置\\\")\\n        print(\\\"-\\\" * 30)\\n        \\n        if self.real_time_detector:\\n            current_stats = self.real_time_detector.get_statistics()\\n            print(f\\\"當前狀態:\\\")\\n            print(f\\\"  監控中: {current_stats['is_monitoring']}\\\")\\n            print(f\\\"  總預測次數: {current_stats['total_predictions']}\\\")\\n            print(f\\\"  總異常次數: {current_stats['total_anomalies']}\\\")\\n            print(f\\\"  異常率: {current_stats['anomaly_rate']:.2f}%\\\")\\n            \\n            # 這裡可以添加互動式參數調整\\n            print(f\\\"\\\\n可調整參數:\\\")\\n            print(f\\\"  警報閾值: {self.real_time_detector.alert_threshold}\\\")\\n            print(f\\\"  連續異常閾值: {self.real_time_detector.consecutive_anomalies_threshold}\\\")\\n            print(f\\\"  時間窗口: {self.real_time_detector.time_window_minutes} 分鐘\\\")\\n\\n# 演示TestSelector與ML的整合\\nprint(\\\"\\\\n🔗 演示TestSelector與ML異常偵測的整合\\\")\\nprint(\\\"=\\\" * 50)\\n\\n# 創建整合演示\\ntest_selector_ml = TestSelectorMLIntegration()\\n\\n# 載入最佳模型\\nif saved_models and evaluation_results:\\n    best_model_name = max(evaluation_results.items(), key=lambda x: x[1]['f1_score'])[0]\\n    best_model_path = saved_models[best_model_name]\\n    \\n    print(f\\\"載入最佳模型: {best_model_name}\\\")\\n    test_selector_ml.enable_ml_detection(model_path=best_model_path, model_type=best_model_name)\\n    \\n    # 啟動實時監控\\n    if test_selector_ml.real_time_detector:\\n        test_selector_ml.real_time_detector.start_monitoring()\\n        print(\\\"🚀 實時監控已啟動\\\")\\n    \\n    # 模擬RA程序分析\\n    print(\\\"\\\\n🧪 模擬RA程序分析...\\\")\\n    \\n    for loop in range(1, 4):\\n        # 模擬RA統計數據\\n        if loop <= 2:\\n            # 前兩個循環：正常行為\\n            mock_ra_stats = {\\n                'success_rate': np.random.normal(95, 3),\\n                'ra_initiated': np.random.randint(8, 12),\\n                'ra_succeeded': 10,\\n                'failed_attempts': 1\\n            }\\n            test_type = 'cots_only'\\n        else:\\n            # 第三個循環：異常行為\\n            mock_ra_stats = {\\n                'success_rate': np.random.normal(65, 10),\\n                'ra_initiated': np.random.randint(18, 25),\\n                'ra_succeeded': 12,\\n                'failed_attempts': 8\\n            }\\n            test_type = 'standard'\\n        \\n        mock_ra_stats['success_rate'] = (mock_ra_stats['ra_succeeded'] / mock_ra_stats['ra_initiated']) * 100\\n        \\n        print(f\\\"\\\\n--- 循環 {loop} ({test_type}) ---\\\")\\n        print(f\\\"RA統計: 啟動={mock_ra_stats['ra_initiated']}, 成功={mock_ra_stats['ra_succeeded']}, 成功率={mock_ra_stats['success_rate']:.1f}%\\\")\\n        \\n        # 執行增強分析\\n        enhanced_stats = test_selector_ml.enhanced_analyze_ra_procedure(\\n            mock_ra_stats, loop, test_type\\n        )\\n        \\n        # 顯示ML分析結果\\n        if 'ml_anomaly_detected' in enhanced_stats:\\n            ml_status = \\\"異常\\\" if enhanced_stats['ml_anomaly_detected'] else \\\"正常\\\"\\n            print(f\\\"ML分析結果: {ml_status} (信心度: {enhanced_stats.get('ml_confidence', 0):.3f})\\\")\\n        \\n        time.sleep(0.5)  # 模擬處理時間\\n    \\n    # 獲取最終統計\\n    time.sleep(1)  # 等待處理完成\\n    final_stats = test_selector_ml.get_ml_statistics()\\n    \\n    print(\\\"\\\\n📊 最終ML統計:\\\")\\n    for key, value in final_stats.items():\\n        print(f\\\"  {key}: {value}\\\")\\n    \\n    # 停止監控\\n    if test_selector_ml.real_time_detector:\\n        test_selector_ml.real_time_detector.stop_monitoring()\\n        print(\\\"\\\\n⏹️ 實時監控已停止\\\")\\n    \\n    # 顯示配置資訊\\n    test_selector_ml.configure_ml_parameters()\\n    \\nelse:\\n    print(\\\"❌ 沒有可用的訓練模型進行整合演示\\\")\\n\\nprint(\\\"\\\\n✅ TestSelector ML整合演示完成\\\")\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb2429c",
   "metadata": {},
   "source": [
    "## 總結與使用建議\n",
    "\n",
    "### 🎯 訓練流程總結\n",
    "\n",
    "本筆記詳細介紹了5G網路ML異常偵測模型的完整訓練流程：\n",
    "\n",
    "1. **特徵工程**: 從RA統計、信號強度、時間戳等原始數據提取25+個特徵\n",
    "2. **數據合成**: 生成正常和異常的合成訓練數據，模擬真實網路行為\n",
    "3. **模型訓練**: 支援無監督（Isolation Forest、One-Class SVM、DBSCAN）和監督學習（Random Forest）\n",
    "4. **模型評估**: 使用準確率、精確率、召回率、F1分數等指標評估性能\n",
    "5. **實時偵測**: 建立多線程實時監控系統，支援閾值調整和警報機制\n",
    "6. **系統整合**: 將ML功能無縫整合到現有的TestSelector測試框架\n",
    "\n",
    "### 🏆 模型選擇建議\n",
    "\n",
    "- **Isolation Forest**: 推薦用於初期測試和部署，無需標記數據，性能穩定\n",
    "- **Random Forest**: 如有足夠的標記異常數據，可提供最高的檢測精度\n",
    "- **One-Class SVM**: 適用於對異常敏感度要求較高的場景\n",
    "- **DBSCAN**: 適用於發現未知的異常模式，但不支援單樣本預測\n",
    "\n",
    "### ⚙️ 部署建議\n",
    "\n",
    "1. **開發階段**: 使用合成數據訓練Isolation Forest模型進行概念驗證\n",
    "2. **測試階段**: 收集真實的正常運行數據，重新訓練無監督模型\n",
    "3. **生產階段**: 積累異常案例後，訓練監督學習模型以提高精度\n",
    "4. **維護階段**: 定期重新訓練模型，適應網路環境變化\n",
    "\n",
    "### 🔧 參數調優指南\n",
    "\n",
    "- **警報閾值**: COTS-only測試建議0.8+，有攻擊者測試建議0.6+\n",
    "- **連續異常閾值**: 建議設為2-3次，平衡敏感度和誤報率\n",
    "- **時間窗口**: 建議5-10分鐘，適應測試循環週期\n",
    "\n",
    "### 🚀 未來改進方向\n",
    "\n",
    "1. **增量學習**: 實作線上學習機制，模型可持續適應新的網路環境\n",
    "2. **多模態融合**: 整合更多數據源（功率、頻譜、流量等）提高檢測能力\n",
    "3. **深度學習**: 探索LSTM、GRU等時序模型捕捉更複雜的異常模式\n",
    "4. **聯邦學習**: 在多個基站間共享學習成果，同時保護隱私\n",
    "5. **可解釋性**: 增加模型決策的可解釋性，幫助工程師理解異常原因\n",
    "\n",
    "### 📋 檢查清單\n",
    "\n",
    "部署前請確認：\n",
    "- [ ] 模型已在足夠的訓練數據上訓練\n",
    "- [ ] 評估指標滿足業務需求（建議F1 > 0.8）\n",
    "- [ ] 警報閾值已根據實際環境調整\n",
    "- [ ] 實時監控系統運行穩定\n",
    "- [ ] 異常處理回調函數已正確配置\n",
    "- [ ] 模型檔案已備份並可快速載入\n",
    "\n",
    "透過本筆記的指導，您應該能夠成功建立和部署一套完整的5G網路ML異常偵測系統。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
